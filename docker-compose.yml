services:
  kafka:
    image: apache/kafka:3.7.0
    volumes:
      - ./kafka-data:/var/lib/kafka/data
      - ./kafka/server.properties:/opt/kafka/config/kraft/server.properties
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      CLUSTER_ID: oGpB7pZbTDeZRhsOcQ9wOg  # any UUID
    command: >
      sh -c "
        if [ ! -f /tmp/meta.properties ]; then
          /opt/kafka/bin/kafka-storage.sh format --config /opt/kafka/config/kraft/server.properties --cluster-id $CLUSTER_ID --ignore-formatted
        fi
        exec /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/kraft/server.properties
      "
    ports:
      - "9092:9092"

  kafka-init:
    image: apache/kafka:3.7.0
    depends_on:
      - kafka
    entrypoint: >
      sh -c "
        until /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list >/dev/null 2>&1; do
          echo 'Waiting for Kafka...'; sleep 2;
        done;
        /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic raw_events --partitions 3 --replication-factor 1 || true
      "

  airflow-init:
    build: .
    depends_on:
      - kafka
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/db/airflow.db
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin
    command: bash -lc "airflow db migrate && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./airflow/db:/opt/airflow/db
      - ./.env:/opt/airflow/.env

  airflow-webserver:
    build: .
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/db/airflow.db
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__LOGGING__BASE_LOG_FOLDER=/opt/airflow/logs
      - AIRFLOW__LOGGING__WORKER_LOG_SERVER_PORT=8793
      - AIRFLOW__LOGGING__WORKER_LOG_SERVER_HOST=airflow-webserver

    command: >
      bash -lc "until airflow db check; do sleep 2; done; exec airflow webserver"
    ports:
      - "8080:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./airflow/db:/opt/airflow/db
      - ./.env:/opt/airflow/.env
      - ./airflow/logs:/opt/airflow/logs


  airflow-scheduler:
    build: .
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/db/airflow.db
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__LOGGING__BASE_LOG_FOLDER=/opt/airflow/logs
      - AIRFLOW__LOGGING__WORKER_LOG_SERVER_PORT=8793
      - AIRFLOW__LOGGING__WORKER_LOG_SERVER_HOST=airflow-webserver
    command: >
      bash -lc "until airflow db check; do sleep 2; done; exec airflow scheduler"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./airflow/db:/opt/airflow/db
      - ./.env:/opt/airflow/.env
      - ./airflow/logs:/opt/airflow/logs

